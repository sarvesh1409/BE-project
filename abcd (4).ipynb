{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9b36c-96c9-4b5b-85ab-1b427ee10df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display,clear_output\n",
    "from warnings import filterwarnings\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\VIKAS\\Desktop\\Final Major Project'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3171296-7e0c-48a7-8e37-804afaccc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
    "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
    "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n",
    "\n",
    "sns.palplot(colors_dark)\n",
    "sns.palplot(colors_green)\n",
    "sns.palplot(colors_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30ea0b7-c0f2-48ef-b4d5-4e2a32cd8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e91bd-3b84-4dc0-a439-8ad9c964c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 150\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(r'C:\\Users\\VIKAS\\Desktop\\Final Major Project\\Brain-Tumor-Classification-DataSet-master (3) (2)\\Brain-Tumor-Classification-DataSet-master\\Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(r'C:\\Users\\VIKAS\\Desktop\\Final Major Project\\Brain-Tumor-Classification-DataSet-master (3) (2)\\Brain-Tumor-Classification-DataSet-master\\Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc256dab-d5ba-4e23-bf91-a579c39a26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "fig, ax = plt.subplots(1,4,figsize=(20,20))\n",
    "fig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\n",
    "for i in labels:\n",
    "    j=0\n",
    "    while True :\n",
    "        if y_train[j]==i:\n",
    "            ax[k].imshow(X_train[j])\n",
    "            ax[k].set_title(y_train[j])\n",
    "            ax[k].axis('off')\n",
    "            k+=1\n",
    "            break\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "033921c9-c4c4-4f16-af58-034ba632ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db4b47-2a3a-4c58-9617-cc11e0dd89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c63a75-1e26-497e-a5ef-27fccba74960",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efec0ef-3ee8-43ae-9566-b1c06371181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of class names to numerical indices\n",
    "label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "\n",
    "# Convert string labels to numeric indices for y_train\n",
    "y_train_new = [label_to_index[label] for label in y_train]\n",
    "\n",
    "# Convert to a NumPy array\n",
    "y_train = np.array(y_train_new)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "# Convert string labels to numeric indices for y_test\n",
    "y_test_new = [label_to_index[label] for label in y_test]\n",
    "\n",
    "# Convert to a NumPy array\n",
    "y_test = np.array(y_test_new)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Check the shape and dtype for both y_train and y_test\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Should be (number_of_samples, number_of_classes)\n",
    "print(f\"y_train dtype: {y_train.dtype}\")  # Should be float32\n",
    "\n",
    "print(f\"y_test shape: {y_test.shape}\")  # Should be (number_of_samples, number_of_classes)\n",
    "print(f\"y_test dtype: {y_test.dtype}\")  # Should be float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f475c4e5-8e92-47a8-9522-c63ad7e9eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0bac3be-9c36-4287-96d7-f06d111f73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = effnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a038d-31e1-4d6b-9d9d-38bde1d30768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44dd6c0-d816-456a-87c6-bb4e9de4efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f0bb03-9e56-4e95-968a-bda8c58f4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "checkpoint = ModelCheckpoint(\"effnet.keras\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcabfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564aae86-6e6c-4053-b4d8-ac7346f34a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ... [previous code up to model.fit()]\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=1, verbose=1, batch_size=32,\n",
    "                    callbacks=[tensorboard, checkpoint, reduce_lr])\n",
    "\n",
    "# Save the model after training\n",
    "model.save(\"final_model.keras\")  # Saving the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a845511-2043-4233-8102-e4ab0a919232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# Ignore warnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Assuming `history` is defined and contains the training history\n",
    "epochs = [i for i in range(len(history.history['accuracy']))]\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Extract data from the history object\n",
    "train_acc = history.history.get('accuracy', [])\n",
    "train_loss = history.history.get('loss', [])\n",
    "val_acc = history.history.get('val_accuracy', [])\n",
    "val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "# Main title\n",
    "fig.suptitle('Epochs vs. Training and Validation Accuracy/Loss', size=18, fontweight='bold', fontname='monospace', color='black', alpha=0.8)\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "sns.despine()\n",
    "ax[0].plot(epochs, train_acc, marker='o', markerfacecolor='green', color='lightgreen', label='Training Accuracy')\n",
    "ax[0].plot(epochs, val_acc, marker='o', markerfacecolor='red', color='lightcoral', label='Validation Accuracy')\n",
    "ax[0].set_title('Accuracy', fontsize=16)\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "sns.despine()\n",
    "ax[1].plot(epochs, train_loss, marker='o', markerfacecolor='green', color='lightgreen', label='Training Loss')\n",
    "ax[1].plot(epochs, val_loss, marker='o', markerfacecolor='red', color='lightcoral', label='Validation Loss')\n",
    "ax[1].set_title('Loss', fontsize=16)\n",
    "ax[1].legend(frameon=False)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "\n",
    "# Show the figure\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a45b6-8163-4010-b8d6-0879fe8cfda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# Check the shape of predictions\n",
    "if pred.shape[1] > 1:  # Multi-class classification\n",
    "    pred = np.argmax(pred, axis=1)  # Get the predicted class indices\n",
    "else:  # Binary classification\n",
    "    pred = (pred > 0.5).astype(int)  # Threshold for binary classification\n",
    "\n",
    "# Convert the true labels from one-hot encoding (if applicable)\n",
    "y_test_new = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Ensure the lengths of predictions and true labels match\n",
    "if len(pred) != len(y_test_new):\n",
    "    raise ValueError(f\"Length of predictions ({len(pred)}) does not match length of true labels ({len(y_test_new)})\")\n",
    "\n",
    "# Evaluate predictions\n",
    "accuracy = accuracy_score(y_test_new, pred)\n",
    "conf_matrix = confusion_matrix(y_test_new, pred)\n",
    "class_report = classification_report(y_test_new, pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b7261-1ba4-486b-85bf-ea5c629f8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# Check the shape of predictions\n",
    "if pred.shape[1] > 1:  # Multi-class classification\n",
    "    pred = np.argmax(pred, axis=1)  # Get the predicted class indices\n",
    "else:  # Binary classification\n",
    "    pred = (pred > 0.5).astype(int)  # Threshold for binary classification\n",
    "\n",
    "# Convert the true labels from one-hot encoding (if applicable)\n",
    "y_test_new = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test_new, pred)\n",
    "print(report)\n",
    "\n",
    "# Optional: Visualize the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_new, pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=np.unique(y_test_new), \n",
    "            yticklabels=np.unique(y_test_new))\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abbb36-146d-41ac-822c-98a9f1e3b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_new, pred)\n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 7))\n",
    "sns.heatmap(conf_matrix, ax=ax, xticklabels=labels, yticklabels=labels, annot=True,\n",
    "            cmap=colors_green[::-1], alpha=0.7, linewidths=2, linecolor=colors_dark[3])\n",
    "\n",
    "# Set title and labels\n",
    "fig.text(s='Heatmap of the Confusion Matrix', size=18, fontweight='bold',\n",
    "         fontname='monospace', color=colors_dark[1], y=0.92, x=0.28, alpha=0.8)\n",
    "\n",
    "# Adjust axis labels for better readability\n",
    "ax.set_xlabel('Predicted Labels', fontsize=14)\n",
    "ax.set_ylabel('True Labels', fontsize=14)\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff2955f-f042-433b-87e2-435b995a7d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e69d1bc7acd4b808e31d41917697c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), Button(description='Predict', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ipywidgets import FileUpload, VBox, Button, Output\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model(\"final_model.keras\")  # Adjust the path if necessary\n",
    "\n",
    "# Create the output widget\n",
    "output = Output()\n",
    "\n",
    "# Function to make a prediction on an uploaded image\n",
    "def img_pred(change):\n",
    "    try:\n",
    "        # Check if any files were uploaded\n",
    "        if uploader.value:\n",
    "            # For debugging: print the structure of uploader.value\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                print(\"uploader.value:\", uploader.value)\n",
    "\n",
    "            # Attempt to get the first uploaded file's content\n",
    "            uploaded_file_info = list(uploader.value.values())[0]\n",
    "            img_content = uploaded_file_info['content']  # Access the image content\n",
    "            \n",
    "            # Convert image content into an image format\n",
    "            img = Image.open(io.BytesIO(img_content))\n",
    "            opencv_image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            img = cv2.resize(opencv_image, (150, 150))\n",
    "            img = img.reshape(1, 150, 150, 3)\n",
    "\n",
    "            # Normalize the image (if your model expects normalized input)\n",
    "            img = img.astype('float32') / 255.0\n",
    "\n",
    "            # Make prediction\n",
    "            p = model.predict(img)\n",
    "            p = np.argmax(p, axis=1)[0]\n",
    "\n",
    "            # Display prediction result\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                if p == 0:\n",
    "                    print('The model predicts: Glioma Tumor')\n",
    "                elif p == 1:\n",
    "                    print('The model predicts: No tumor')\n",
    "                elif p == 2:\n",
    "                    print('The model predicts: Meningioma Tumor')\n",
    "                else:\n",
    "                    print('The model predicts: Pituitary Tumor')\n",
    "        else:\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                print(\"No file uploaded.\")\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create the FileUpload widget\n",
    "uploader = FileUpload(accept='image/*', multiple=False)\n",
    "\n",
    "# Create a button to trigger the prediction\n",
    "predict_button = Button(description='Predict')\n",
    "\n",
    "# Attach the img_pred function to the predict button's click event\n",
    "predict_button.on_click(img_pred)\n",
    "\n",
    "# Display the widgets vertically\n",
    "display(VBox([uploader, predict_button, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89305f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e475086c18419797be3e6be403f88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), Button(description='Predict', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Raw prediction output: [[2.6461351e-20 2.1556251e-32 1.0000000e+00 7.6732739e-21]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Raw prediction output: [[0. 0. 1. 0.]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Raw prediction output: [[1.9271937e-19 6.1880440e-33 1.0000000e+00 1.5958471e-20]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "Raw prediction output: [[3.4562587e-34 0.0000000e+00 1.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def img_pred(change):\n",
    "    try:\n",
    "        # Check if any files were uploaded\n",
    "        if uploader.value:\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                print(\"uploader.value:\", uploader.value)\n",
    "\n",
    "            uploaded_file_info = uploader.value[0]\n",
    "            img_content = uploaded_file_info['content']\n",
    "            \n",
    "            # Convert image content into an image format\n",
    "            img = Image.open(io.BytesIO(img_content))\n",
    "            opencv_image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            img = cv2.resize(opencv_image, (150, 150))\n",
    "            img = img.reshape(1, 150, 150, 3)\n",
    "            img = img.astype('float32') / 255.0\n",
    "\n",
    "            # Make prediction\n",
    "            p = model.predict(img)\n",
    "            print(\"Raw prediction output:\", p)  # Print the model's raw prediction\n",
    "            \n",
    "            # Determine predicted class\n",
    "            predicted_class = np.argmax(p, axis=1)[0]\n",
    "            predicted_probability = p[0][predicted_class]\n",
    "\n",
    "            # Display prediction result\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                if predicted_class == 0:\n",
    "                    print('The model predicts: Glioma Tumor (Confidence: {:.2f})'.format(predicted_probability))\n",
    "                elif predicted_class == 1:\n",
    "                    print('The model predicts: No Tumor (Confidence: {:.2f})'.format(predicted_probability))\n",
    "                elif predicted_class == 2:\n",
    "                    print('The model predicts: Meningioma Tumor (Confidence: {:.2f})'.format(predicted_probability))\n",
    "                else:\n",
    "                    print('The model predicts: Pituitary Tumor (Confidence: {:.2f})'.format(predicted_probability))\n",
    "        else:\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                print(\"No file uploaded.\")\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Error:\", e)\n",
    "# Create the FileUpload widget\n",
    "uploader = FileUpload(accept='image/*', multiple=False)\n",
    "\n",
    "# Create a button to trigger the prediction\n",
    "predict_button = Button(description='Predict')\n",
    "\n",
    "# Attach the img_pred function to the predict button's click event\n",
    "predict_button.on_click(img_pred)\n",
    "\n",
    "# Display the widgets vertically\n",
    "display(VBox([uploader, predict_button, output]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
